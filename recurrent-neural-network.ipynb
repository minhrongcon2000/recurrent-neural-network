{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network In Binary Addition\n",
    "## Abstract\n",
    "This notebook is about the usage of Recurrent Neural Network (RNN) in adding two binary numbers.\n",
    "\n",
    "## Introduction\n",
    "### What is a recurrent neural network?\n",
    "As far as you know, neural network is a collection of matrix operation that can approximate the connection between features and labels in a dataset. Basic neural network includes an input layer, some hidden units, and an output layer. However, because of using so much parameters, basic NN model is easily to overfit the dataset, which causes the model to have poor performances. Therefore, there are a lot of improvement to neural network; in other words, researchers are now optimizing neural network for some specific use cases. For instance, when it comes to image processing, convolutional neural network is the best model to be used. However, what if the order of each data point matter to the overall result? This is what RNN serves. Basic NN's hidden layer take the input from the previous layer to get the output; thus, it just takes fix-sized input and output fix-sized output. With the RNN, each data point is splited into time steps. At each time steps, not only does RNN take the input from the data point at the current time step, but it also takes the input from the hidden layer from the previous time step. The figure below is an illustration of RNN. Thanks to this special mechanism, RNN is perharps the best model in every dataset that the order matters.\n",
    "\n",
    "![rnn](https://cdn-images-1.medium.com/max/1600/1*4KwIUHWL3sTyguTahIxmJw.png)\n",
    "\n",
    "## Let's jump into code\n",
    "First, we need to import our dependencies. Details about each dependency are written in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # matrix operations\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "from data import * #generate data\n",
    "from activation import * # activation functions\n",
    "from loss import * # loss function\n",
    "from utils import * # postprocessing data\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0) # help the dataset remain the same in each execution, useful for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to specify some hyperparameters. Hyperparameters are numerical value that does not include in the training process but still have a major impact on the overall performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_unit = 8 # number of hidden units\n",
    "output_unit = 1 # number of output units\n",
    "binary_bit = 4 # number of bits \n",
    "display_step = 100 # when model displays results\n",
    "largest_num = 2**binary_bit-1 #the largest number with given number of bits\n",
    "num_ex=50 # number of training examples we want to generate\n",
    "alpha = 0.001 # learning rate\n",
    "training_iter = 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we have to randomly initialize our parameters, which are weights and biases. We will build a RNN with two input units, eight hidden units, and one output unit, so\n",
    "* the weight way that connects the hidden layer with the output layer is an output unit x hidden unit matrix\n",
    "* the weight wax that connects the input layer with the hidden layer is a hidden unit x input unit matrix\n",
    "* the weight waa that connects the hidden layers of two consecutive hidden layers is a hidden unit x hidden unit matrix\n",
    "* the bias ba that connects the input layer with the hidden layer is a column vector whose size is equal to the number of hidden unit\n",
    "* the bias by that connects the hidden layer with the output layer is a column vector whose size is equal to the number of output unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "wax = 2*np.random.random((hidden_unit,2)) - 1 # weight used to connect the input layer with the hidden layer\n",
    "waa = 2*np.random.random((hidden_unit,hidden_unit)) - 1 # weight used to connect two consecutive hidden layers\n",
    "way = 2*np.random.random((output_unit,hidden_unit)) - 1# weight used to connect the hidden layer with the output layer\n",
    "ba = 2*np.random.random((hidden_unit,1)) - 1 # bias used to connect the input layer with the hidden layer\n",
    "by = 2*np.random.random((output_unit,1)) - 1 # bias used to connect the hidden layer with the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to have a dataset. For the simplicity, we will generate the dataset by ourself. The function used to generate dataset is written in the file 'data.py'. Feel free to check that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataset\n",
    "m,n,p = datagen(num_ex,binary_bit)\n",
    "\n",
    "m_seq = np.zeros((m.shape[0],binary_bit))\n",
    "n_seq = np.zeros((n.shape[0],binary_bit))\n",
    "p_seq = np.zeros((p.shape[0],binary_bit))\n",
    "\n",
    "for ex_index in range(m.shape[0]):\n",
    "\tm_seq[ex_index] = [float(bits) for bits in int2binary(m[ex_index][0],binary_bit)]\n",
    "\tn_seq[ex_index] = [float(bits) for bits in int2binary(n[ex_index][0],binary_bit)]\n",
    "\tp_seq[ex_index] = [float(bits) for bits in int2binary(p[ex_index][0],binary_bit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the code readability, we will specify a dictionary that contains all the hidden matrix and output matrix at every time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hidden layer matrices\n",
    "a = {0: np.zeros((hidden_unit,m.shape[0]))}\n",
    "\n",
    "# predictions\n",
    "pred = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to step into the training step. The training process includes two steps: the forward pass and the backward pass. Each pass includes some matrix operation.\n",
    "\n",
    "## Forward pass\n",
    "\n",
    "$$a^{<0>}=\\overrightarrow{0}$$\n",
    "\n",
    "$$a^{<t>}=\\tanh(W_{ax}x^{<t>}+W_{aa}a^{<t-1>}+b_a),\\text{ }\\forall t\\geq 1$$\n",
    "\n",
    "$$\\widehat{y}^{<t>}=sigmoid(W_{ay}a^{<t>}+b_y),\\text{ }\\forall t\\geq 1$$\n",
    "\n",
    "## Backward pass (Backpropagation)\n",
    "This is the process of taking the derivative of the loss function with respeact to each weight. The loss function we use here is expressed as follow:\n",
    "* At the timestep $t$, $$\\mathcal{L}^{<t>}(y^{<t>},\\widehat{y}^{<t>})=-y^{<t>}*\\log(\\widehat{y}^{<t>})-(1-y^{<t>})*\\log(1-\\widehat{y}^{<t>})$$\n",
    "* The overall loss is $$\\mathcal{L}=\\sum_{t}\\mathcal{L}^{<t>}(y^{<t>},\\widehat{y}^{<t>})$$\n",
    "\n",
    "In the training step, we will treat each bit as input for each timestep and take the last binary bit as the first timestep. This means that the last binary bit is the input for $t=1$. We do the forward pass and then backward pass to update our parameters, making the model better and better after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Iteration 0\n",
      "Loss 150.21906399989592\n",
      "6 + 0 = 15\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 100\n",
      "Loss 117.89824102412551\n",
      "4 + 3 = 15\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 200\n",
      "Loss 102.22051138856696\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 300\n",
      "Loss 81.96352804125291\n",
      "3 + 1 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 400\n",
      "Loss 55.937760933602334\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 500\n",
      "Loss 38.8359694359998\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 600\n",
      "Loss 30.14246265269674\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 700\n",
      "Loss 25.193730075103062\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 800\n",
      "Loss 22.23983795275349\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 900\n",
      "Loss 20.23025494320608\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 1000\n",
      "Loss 18.585019190311904\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 1100\n",
      "Loss 17.060446670363625\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 1200\n",
      "Loss 15.407651512305357\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 1300\n",
      "Loss 13.144727059034935\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 1400\n",
      "Loss 10.636826504111\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 1500\n",
      "Loss 9.045456159392819\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 1600\n",
      "Loss 7.957579915067799\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 1700\n",
      "Loss 7.134081964339982\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 1800\n",
      "Loss 6.484247101959664\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 1900\n",
      "Loss 5.961483767082053\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 2000\n",
      "Loss 5.536748212959669\n",
      "0 + 1 = 1\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 2100\n",
      "Loss 5.1891737261245\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 2200\n",
      "Loss 4.902498035016318\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 2300\n",
      "Loss 4.663607135240423\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 2400\n",
      "Loss 4.461975497963689\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 2500\n",
      "Loss 4.2894553964075195\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 2600\n",
      "Loss 4.139977225457374\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 2700\n",
      "Loss 4.009071573909407\n",
      "6 + 1 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 2800\n",
      "Loss 3.893394853958543\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 2900\n",
      "Loss 3.7903806171700145\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 3000\n",
      "Loss 3.698013653372982\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 3100\n",
      "Loss 3.614684643502574\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 3200\n",
      "Loss 3.539092154195905\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 3300\n",
      "Loss 3.470173069115145\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 3400\n",
      "Loss 3.407051323940812\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 3500\n",
      "Loss 3.34899921352959\n",
      "2 + 4 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 3600\n",
      "Loss 3.2954077291437933\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 3700\n",
      "Loss 3.2457635637832114\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 3800\n",
      "Loss 3.199631128693191\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 3900\n",
      "Loss 3.1566383821124364\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 4000\n",
      "Loss 3.116465585566533\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 4100\n",
      "Loss 3.0788363259381084\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 4200\n",
      "Loss 3.0435103030930675\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 4300\n",
      "Loss 3.010277501705139\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 4400\n",
      "Loss 2.9789534544246776\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 4500\n",
      "Loss 2.9493753700892302\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 4600\n",
      "Loss 2.9213989511322462\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 4700\n",
      "Loss 2.894895762870668\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 4800\n",
      "Loss 2.8697510469373455\n",
      "2 + 4 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 4900\n",
      "Loss 2.845861893958942\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 5000\n",
      "Loss 2.8231357082827544\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 5100\n",
      "Loss 2.801488911335303\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 5200\n",
      "Loss 2.7808458409620926\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 5300\n",
      "Loss 2.761137812541754\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 5400\n",
      "Loss 2.7423023143148058\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 5500\n",
      "Loss 2.7242823146193325\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 5600\n",
      "Loss 2.707025662892305\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 5700\n",
      "Loss 2.6904845696134188\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 5800\n",
      "Loss 2.6746151530220548\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 5900\n",
      "Loss 2.659377042568938\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 6000\n",
      "Loss 2.6447330307833536\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 6100\n",
      "Loss 2.630648766629023\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 6200\n",
      "Loss 2.6170924845552763\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 6300\n",
      "Loss 2.6040347643762844\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 6400\n",
      "Loss 2.591448317871716\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 6500\n",
      "Loss 2.5793077986293294\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 6600\n",
      "Loss 2.5675896321696188\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 6700\n",
      "Loss 2.556271863824832\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 6800\n",
      "Loss 2.5453340222056178\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 6900\n",
      "Loss 2.5347569963917502\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 7000\n",
      "Loss 2.524522925238193\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 7100\n",
      "Loss 2.514615097403703\n",
      "6 + 1 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 7200\n",
      "Loss 2.5050178608922082\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 7300\n",
      "Loss 2.4957165410530036\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 7400\n",
      "Loss 2.486697366119362\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 7500\n",
      "Loss 2.477947399479127\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 7600\n",
      "Loss 2.469454477969452\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 7700\n",
      "Loss 2.4612071555726662\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 7800\n",
      "Loss 2.45319465196338\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 7900\n",
      "Loss 2.4454068054210945\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 8000\n",
      "Loss 2.4378340296777004\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 8100\n",
      "Loss 2.430467274317675\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 8200\n",
      "Loss 2.4232979883911194\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 8300\n",
      "Loss 2.4163180869367338\n",
      "0 + 0 = 0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Iteration 8400\n",
      "Loss 2.4095199201444144\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 8500\n",
      "Loss 2.402896244915741\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 8600\n",
      "Loss 2.396440198605898\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 8700\n",
      "Loss 2.390145274752779\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 8800\n",
      "Loss 2.38400530061891\n",
      "6 + 1 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 8900\n",
      "Loss 2.3780144163891213\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 9000\n",
      "Loss 2.372167055882581\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 9100\n",
      "Loss 2.3664579286515037\n",
      "2 + 0 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 9200\n",
      "Loss 2.360882003351306\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 9300\n",
      "Loss 2.3554344922776638\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 9400\n",
      "Loss 2.350110836976081\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 9500\n",
      "Loss 2.344906694838076\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 9600\n",
      "Loss 2.3398179266060986\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 9700\n",
      "Loss 2.334840584716187\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 9800\n",
      "Loss 2.329970902413943\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 9900\n",
      "Loss 2.3252052835847974\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 10000\n",
      "Loss 2.320540293244901\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 10100\n",
      "Loss 2.3159726486434438\n",
      "6 + 6 = 8\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 10200\n",
      "Loss 2.3114992109314776\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 10300\n",
      "Loss 2.3071169773559808\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 10400\n",
      "Loss 2.3028230739414224\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 10500\n",
      "Loss 2.2986147486240665\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 10600\n",
      "Loss 2.2944893648071374\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 10700\n",
      "Loss 2.2904443953074516\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 10800\n",
      "Loss 2.2864774166664983\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 10900\n",
      "Loss 2.282586103800953\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 11000\n",
      "Loss 2.2787682249696424\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 11100\n",
      "Loss 2.2750216370356675\n",
      "2 + 0 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 11200\n",
      "Loss 2.271344281003954\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 11300\n",
      "Loss 2.2677341778160343\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 11400\n",
      "Loss 2.2641894243851852\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 11500\n",
      "Loss 2.2607081898561945\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 11600\n",
      "Loss 2.2572887120753062\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 11700\n",
      "Loss 2.2539292942567055\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 11800\n",
      "Loss 2.2506283018331374\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 11900\n",
      "Loss 2.247384159478839\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 12000\n",
      "Loss 2.2441953482939647\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 12100\n",
      "Loss 2.24106040314037\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 12200\n",
      "Loss 2.2379779101192443\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 12300\n",
      "Loss 2.2349465041818424\n",
      "2 + 0 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 12400\n",
      "Loss 2.231964866864962\n",
      "6 + 6 = 8\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 12500\n",
      "Loss 2.2290317241435877\n",
      "3 + 5 = 8\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 12600\n",
      "Loss 2.2261458443933835\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 12700\n",
      "Loss 2.223306036456342\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 12800\n",
      "Loss 2.220511147803256\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 12900\n",
      "Loss 2.217760062787106\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 13000\n",
      "Loss 2.2150517009817134\n",
      "3 + 6 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 13100\n",
      "Loss 2.2123850156005784\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 13200\n",
      "Loss 2.2097589919908187\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 13300\n",
      "Loss 2.2071726461977392\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 13400\n",
      "Loss 2.204625023595572\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 13500\n",
      "Loss 2.202115197580213\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 13600\n",
      "Loss 2.1996422683202677\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 13700\n",
      "Loss 2.197205361562497\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 13800\n",
      "Loss 2.194803627488286\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 13900\n",
      "Loss 2.1924362396177512\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 14000\n",
      "Loss 2.190102393758385\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 14100\n",
      "Loss 2.187801306995112\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 14200\n",
      "Loss 2.1855322167189244\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 14300\n",
      "Loss 2.1832943796913025\n",
      "3 + 6 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 14400\n",
      "Loss 2.181087071141656\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 14500\n",
      "Loss 2.178909583895278\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 14600\n",
      "Loss 2.176761227529153\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 14700\n",
      "Loss 2.17464132755331\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 14800\n",
      "Loss 2.172549224615032\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 14900\n",
      "Loss 2.1704842737237544\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 15000\n",
      "Loss 2.1684458434941263\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 15100\n",
      "Loss 2.1664333154048414\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 15200\n",
      "Loss 2.164446083070867\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 15300\n",
      "Loss 2.1624835515265777\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 15400\n",
      "Loss 2.1605451365173556\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 15500\n",
      "Loss 2.158630263797006\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 15600\n",
      "Loss 2.156738368428403\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 15700\n",
      "Loss 2.1548688940845198\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 15800\n",
      "Loss 2.1530212923469776\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 15900\n",
      "Loss 2.1511950219989884\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 16000\n",
      "Loss 2.1493895483093786\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 16100\n",
      "Loss 2.14760434230424\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 16200\n",
      "Loss 2.1458388800222856\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 16300\n",
      "Loss 2.1440926417498543\n",
      "6 + 6 = 8\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Iteration 16400\n",
      "Loss 2.1423651112309714\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 16500\n",
      "Loss 2.1406557748475508\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 16600\n",
      "Loss 2.138964120764246\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 16700\n",
      "Loss 2.137289638031816\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 16800\n",
      "Loss 2.1356318156423284\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 16900\n",
      "Loss 2.1339901415285154\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 17000\n",
      "Loss 2.1323641014988977\n",
      "6 + 6 = 8\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 17100\n",
      "Loss 2.130753178098948\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 17200\n",
      "Loss 2.129156849387578\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 17300\n",
      "Loss 2.1275745876164964\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 17400\n",
      "Loss 2.1260058577984884\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 17500\n",
      "Loss 2.124450116148491\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 17600\n",
      "Loss 2.122906808379051\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 17700\n",
      "Loss 2.12137536782893\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 17800\n",
      "Loss 2.1198552134004345\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 17900\n",
      "Loss 2.118345747276931\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 18000\n",
      "Loss 2.1168463523877374\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 18100\n",
      "Loss 2.115356389581661\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 18200\n",
      "Loss 2.1138751944643723\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 18300\n",
      "Loss 2.1124020738464826\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 18400\n",
      "Loss 2.110936301740079\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 18500\n",
      "Loss 2.1094771148298435\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 18600\n",
      "Loss 2.108023707331171\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 18700\n",
      "Loss 2.1065752251307184\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 18800\n",
      "Loss 2.1051307590843797\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 18900\n",
      "Loss 2.1036893373221903\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 19000\n",
      "Loss 2.1022499163786383\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 19100\n",
      "Loss 2.1008113709280263\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 19200\n",
      "Loss 2.0993724818563178\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 19300\n",
      "Loss 2.0979319223403143\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 19400\n",
      "Loss 2.096488241529038\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 19500\n",
      "Loss 2.095039845325067\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 19600\n",
      "Loss 2.0935849736404046\n",
      "3 + 6 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 19700\n",
      "Loss 2.0921216733427146\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 19800\n",
      "Loss 2.0906477659022293\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 19900\n",
      "Loss 2.089160808482015\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 20000\n",
      "Loss 2.087658046861909\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 20100\n",
      "Loss 2.0861363581197065\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 20200\n",
      "Loss 2.084592180368621\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 20300\n",
      "Loss 2.0830214260062534\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 20400\n",
      "Loss 2.0814193737793123\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 20500\n",
      "Loss 2.079780533379838\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 20600\n",
      "Loss 2.0780984740717243\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 20700\n",
      "Loss 2.076365605712011\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 20800\n",
      "Loss 2.0745728960404164\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 20900\n",
      "Loss 2.072709501579628\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 21000\n",
      "Loss 2.0707622798403067\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 21100\n",
      "Loss 2.068715136021299\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 21200\n",
      "Loss 2.0665481351804678\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 21300\n",
      "Loss 2.0642362761158792\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 21400\n",
      "Loss 2.0617477676404126\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 21500\n",
      "Loss 2.059041556826429\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 21600\n",
      "Loss 2.056063705195919\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 21700\n",
      "Loss 2.0527419417497486\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 21800\n",
      "Loss 2.048977240999761\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 21900\n",
      "Loss 2.0446303745890417\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 22000\n",
      "Loss 2.0394996262140883\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 22100\n",
      "Loss 2.033282245805394\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 22200\n",
      "Loss 2.0255043693790302\n",
      "6 + 6 = 8\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 22300\n",
      "Loss 2.0153860114582867\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 22400\n",
      "Loss 2.0015632714780236\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 22500\n",
      "Loss 1.9814758721751669\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 22600\n",
      "Loss 1.9499465228318313\n",
      "3 + 6 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 22700\n",
      "Loss 1.8960478011493627\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 22800\n",
      "Loss 1.799406996668104\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 22900\n",
      "Loss 1.6490984174135808\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 23000\n",
      "Loss 1.5032033338151383\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 23100\n",
      "Loss 1.402156678607078\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 23200\n",
      "Loss 1.3166116518923892\n",
      "2 + 4 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 23300\n",
      "Loss 1.2229603332988592\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 23400\n",
      "Loss 1.1214911815478692\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 23500\n",
      "Loss 1.0234210554204246\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 23600\n",
      "Loss 0.937285475046561\n",
      "0 + 1 = 1\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 23700\n",
      "Loss 0.8654236053827326\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 23800\n",
      "Loss 0.8064505195579305\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 23900\n",
      "Loss 0.7578674120762302\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 24000\n",
      "Loss 0.717302453483265\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 24100\n",
      "Loss 0.682862036030161\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 24200\n",
      "Loss 0.6531284343952461\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 24300\n",
      "Loss 0.6270629128013958\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 24400\n",
      "Loss 0.6039057392025834\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 24500\n",
      "Loss 0.5830966148896044\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 24600\n",
      "Loss 0.5642167106769216\n",
      "4 + 0 = 4\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Iteration 24700\n",
      "Loss 0.5469478945067734\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 24800\n",
      "Loss 0.5310443950353999\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 24900\n",
      "Loss 0.5163131160663077\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 25000\n",
      "Loss 0.5025998763724363\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 25100\n",
      "Loss 0.48977969404607546\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 25200\n",
      "Loss 0.47774984094049683\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 25300\n",
      "Loss 0.46642480885313775\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 25400\n",
      "Loss 0.45573260870949933\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 25500\n",
      "Loss 0.44561201036655507\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 25600\n",
      "Loss 0.4360104547527762\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 25700\n",
      "Loss 0.4268824530093826\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 25800\n",
      "Loss 0.41818834311694186\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 25900\n",
      "Loss 0.4098933123882972\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 26000\n",
      "Loss 0.4019666202010936\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 26100\n",
      "Loss 0.39438097336938227\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 26200\n",
      "Loss 0.38711201920170407\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 26300\n",
      "Loss 0.3801379302736896\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 26400\n",
      "Loss 0.3734390613971364\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 26500\n",
      "Loss 0.36699766396037636\n",
      "2 + 4 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 26600\n",
      "Loss 0.36079764626734284\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 26700\n",
      "Loss 0.35482437106990244\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 26800\n",
      "Loss 0.34906448341751295\n",
      "3 + 6 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 26900\n",
      "Loss 0.343505763411083\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 27000\n",
      "Loss 0.3381369995674698\n",
      "2 + 0 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 27100\n",
      "Loss 0.3329478793634069\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 27200\n",
      "Loss 0.32792889419721427\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 27300\n",
      "Loss 0.3230712565290285\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 27400\n",
      "Loss 0.3183668273710372\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 27500\n",
      "Loss 0.3138080526229778\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 27600\n",
      "Loss 0.30938790700584023\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 27700\n",
      "Loss 0.3050998445525107\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 27800\n",
      "Loss 0.3009377547795771\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 27900\n",
      "Loss 0.29689592379899127\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 28000\n",
      "Loss 0.29296899973774027\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 28100\n",
      "Loss 0.28915196192429365\n",
      "6 + 1 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 28200\n",
      "Loss 0.2854400933756181\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 28300\n",
      "Loss 0.28182895618144727\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 28400\n",
      "Loss 0.2783143694359244\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 28500\n",
      "Loss 0.27489238941179245\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 28600\n",
      "Loss 0.27155929171142174\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 28700\n",
      "Loss 0.26831155516216887\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 28800\n",
      "Loss 0.26514584725296364\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 28900\n",
      "Loss 0.262059010934021\n",
      "0 + 1 = 1\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 29000\n",
      "Loss 0.25904805262375313\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 29100\n",
      "Loss 0.25611013128635784\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 29200\n",
      "Loss 0.2532425484602626\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 29300\n",
      "Loss 0.2504427391326372\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 29400\n",
      "Loss 0.24770826336815474\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 29500\n",
      "Loss 0.2450367986114601\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 29600\n",
      "Loss 0.24242613259295007\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 29700\n",
      "Loss 0.23987415677615698\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 29800\n",
      "Loss 0.2373788602925387\n",
      "6 + 1 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 29900\n",
      "Loss 0.2349383243164004\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 30000\n",
      "Loss 0.2325507168380913\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 30100\n",
      "Loss 0.23021428779910988\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 30200\n",
      "Loss 0.2279273645566555\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 30300\n",
      "Loss 0.22568834764930482\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 30400\n",
      "Loss 0.22349570683855952\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 30500\n",
      "Loss 0.22134797740396137\n",
      "2 + 4 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 30600\n",
      "Loss 0.21924375667175075\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 30700\n",
      "Loss 0.21718170075942358\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 30800\n",
      "Loss 0.21516052151998985\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 30900\n",
      "Loss 0.21317898367171212\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 31000\n",
      "Loss 0.21123590210009283\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 31100\n",
      "Loss 0.20933013932040437\n",
      "2 + 0 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 31200\n",
      "Loss 0.20746060308980968\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 31300\n",
      "Loss 0.20562624415917033\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 31400\n",
      "Loss 0.20382605415545132\n",
      "3 + 5 = 8\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 31500\n",
      "Loss 0.20205906358624745\n",
      "2 + 0 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 31600\n",
      "Loss 0.2003243399586749\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 31700\n",
      "Loss 0.19862098600530181\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 31800\n",
      "Loss 0.19694813801052863\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 31900\n",
      "Loss 0.1953049642310386\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 32000\n",
      "Loss 0.19369066340447802\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 32100\n",
      "Loss 0.19210446334098497\n",
      "3 + 6 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 32200\n",
      "Loss 0.19054561959239147\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 32300\n",
      "Loss 0.18901341419428028\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 32400\n",
      "Loss 0.18750715447658978\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 32500\n",
      "Loss 0.1860261719383944\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 32600\n",
      "Loss 0.184569821183034\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 32700\n",
      "Loss 0.18313747890995377\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 32800\n",
      "Loss 0.18172854295974103\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 32900\n",
      "Loss 0.1803424314091946\n",
      "3 + 4 = 7\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Iteration 33000\n",
      "Loss 0.1789785817133877\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 33100\n",
      "Loss 0.17763644989197047\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 33200\n",
      "Loss 0.176315509756925\n",
      "3 + 6 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 33300\n",
      "Loss 0.1750152521795291\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 33400\n",
      "Loss 0.17373518439398758\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 33500\n",
      "Loss 0.17247482933574038\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 33600\n",
      "Loss 0.17123372501233944\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 33700\n",
      "Loss 0.17001142390503024\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 33800\n",
      "Loss 0.16880749239928713\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 33900\n",
      "Loss 0.16762151024258182\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 34000\n",
      "Loss 0.1664530700279395\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 34100\n",
      "Loss 0.16530177670173607\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 34200\n",
      "Loss 0.16416724709443262\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 34300\n",
      "Loss 0.16304910947296034\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 34400\n",
      "Loss 0.16194700311359184\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 34500\n",
      "Loss 0.16086057789410582\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 34600\n",
      "Loss 0.15978949390434277\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 34700\n",
      "Loss 0.15873342107401192\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 34800\n",
      "Loss 0.15769203881697258\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 34900\n",
      "Loss 0.15666503569098406\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 35000\n",
      "Loss 0.15565210907227536\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 35100\n",
      "Loss 0.15465296484403893\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 35200\n",
      "Loss 0.15366731709822276\n",
      "2 + 4 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 35300\n",
      "Loss 0.15269488784989954\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 35400\n",
      "Loss 0.15173540676359437\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 35500\n",
      "Loss 0.15078861089098172\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 35600\n",
      "Loss 0.1498542444194266\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 35700\n",
      "Loss 0.14893205843074786\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 35800\n",
      "Loss 0.14802181066981593\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 35900\n",
      "Loss 0.1471232653224343\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 36000\n",
      "Loss 0.1462361928021184\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 36100\n",
      "Loss 0.14536036954531584\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 36200\n",
      "Loss 0.1444955778146811\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 36300\n",
      "Loss 0.1436416055100587\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 36400\n",
      "Loss 0.14279824598678673\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 36500\n",
      "Loss 0.14196529788098924\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 36600\n",
      "Loss 0.14114256494160074\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 36700\n",
      "Loss 0.14032985586870067\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 36800\n",
      "Loss 0.13952698415802214\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 36900\n",
      "Loss 0.1387337679512314\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 37000\n",
      "Loss 0.1379500298918344\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 37100\n",
      "Loss 0.1371755969863867\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 37200\n",
      "Loss 0.13641030047080627\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 37300\n",
      "Loss 0.13565397568159251\n",
      "3 + 5 = 8\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 37400\n",
      "Loss 0.13490646193168648\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 37500\n",
      "Loss 0.1341676023908542\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 37600\n",
      "Loss 0.1334372439703277\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 37700\n",
      "Loss 0.13271523721155798\n",
      "0 + 1 = 1\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 37800\n",
      "Loss 0.13200143617893814\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 37900\n",
      "Loss 0.13129569835628196\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 38000\n",
      "Loss 0.13059788454692958\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 38100\n",
      "Loss 0.1299078587773272\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 38200\n",
      "Loss 0.12922548820399143\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 38300\n",
      "Loss 0.12855064302356878\n",
      "2 + 0 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 38400\n",
      "Loss 0.1278831963860936\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 38500\n",
      "Loss 0.12722302431112967\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 38600\n",
      "Loss 0.12657000560676163\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 38700\n",
      "Loss 0.1259240217913081\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 38800\n",
      "Loss 0.1252849570176696\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 38900\n",
      "Loss 0.12465269800018186\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 39000\n",
      "Loss 0.12402713394389632\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 39100\n",
      "Loss 0.12340815647619123\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 39200\n",
      "Loss 0.12279565958060305\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 39300\n",
      "Loss 0.12218953953284212\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 39400\n",
      "Loss 0.12158969483886618\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 39500\n",
      "Loss 0.12099602617493507\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 39600\n",
      "Loss 0.12040843632963331\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 39700\n",
      "Loss 0.11982683014767577\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 39800\n",
      "Loss 0.1192511144755623\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 39900\n",
      "Loss 0.11868119810889359\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 40000\n",
      "Loss 0.11811699174138146\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 40100\n",
      "Loss 0.11755840791543457\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 40200\n",
      "Loss 0.11700536097427756\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 40300\n",
      "Loss 0.11645776701555281\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 40400\n",
      "Loss 0.11591554384636275\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 40500\n",
      "Loss 0.11537861093967242\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 40600\n",
      "Loss 0.11484688939204006\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 40700\n",
      "Loss 0.11432030188264691\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 40800\n",
      "Loss 0.11379877263355373\n",
      "5 + 0 = 5\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Iteration 40900\n",
      "Loss 0.11328222737114356\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 41000\n",
      "Loss 0.1127705932887085\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 41100\n",
      "Loss 0.11226379901018368\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 41200\n",
      "Loss 0.11176177455491945\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 41300\n",
      "Loss 0.11126445130351738\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 41400\n",
      "Loss 0.11077176196462502\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 41500\n",
      "Loss 0.11028364054274814\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 41600\n",
      "Loss 0.10980002230698133\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 41700\n",
      "Loss 0.10932084376062587\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 41800\n",
      "Loss 0.1088460426116852\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 41900\n",
      "Loss 0.10837555774422009\n",
      "6 + 1 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 42000\n",
      "Loss 0.10790932919051205\n",
      "0 + 1 = 1\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 42100\n",
      "Loss 0.10744729810400926\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 42200\n",
      "Loss 0.10698940673304708\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 42300\n",
      "Loss 0.10653559839529238\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 42400\n",
      "Loss 0.10608581745290127\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 42500\n",
      "Loss 0.10564000928840916\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 42600\n",
      "Loss 0.10519812028121209\n",
      "6 + 1 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 42700\n",
      "Loss 0.10476009778478614\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 42800\n",
      "Loss 0.10432589010444447\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 42900\n",
      "Loss 0.10389544647576557\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 43000\n",
      "Loss 0.10346871704358997\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 43100\n",
      "Loss 0.1030456528415709\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 43200\n",
      "Loss 0.10262620577228701\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 43300\n",
      "Loss 0.10221032858790258\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 43400\n",
      "Loss 0.10179797487131564\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 43500\n",
      "Loss 0.10138909901783046\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 43600\n",
      "Loss 0.10098365621729914\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 43700\n",
      "Loss 0.1005816024367569\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 43800\n",
      "Loss 0.10018289440347766\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 43900\n",
      "Loss 0.09978748958852043\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 44000\n",
      "Loss 0.09939534619064709\n",
      "3 + 5 = 8\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 44100\n",
      "Loss 0.09900642312071557\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 44200\n",
      "Loss 0.09862067998641277\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 44300\n",
      "Loss 0.09823807707744255\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 44400\n",
      "Loss 0.09785857535103952\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 44500\n",
      "Loss 0.09748213641790089\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 44600\n",
      "Loss 0.09710872252842494\n",
      "6 + 6 = 12\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 44700\n",
      "Loss 0.09673829655933955\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 44800\n",
      "Loss 0.09637082200062928\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 44900\n",
      "Loss 0.09600626294281998\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 45000\n",
      "Loss 0.09564458406457198\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 45100\n",
      "Loss 0.0952857506205739\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 45200\n",
      "Loss 0.09492972842973922\n",
      "3 + 5 = 8\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 45300\n",
      "Loss 0.09457648386369949\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 45400\n",
      "Loss 0.09422598383557246\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 45500\n",
      "Loss 0.09387819578900199\n",
      "3 + 6 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 45600\n",
      "Loss 0.09353308768745852\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 45700\n",
      "Loss 0.09319062800385562\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 45800\n",
      "Loss 0.09285078571031087\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 45900\n",
      "Loss 0.09251353026824664\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 46000\n",
      "Loss 0.09217883161869428\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 46100\n",
      "Loss 0.09184666017280521\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 46200\n",
      "Loss 0.09151698680263701\n",
      "2 + 4 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 46300\n",
      "Loss 0.09118978283211955\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 46400\n",
      "Loss 0.09086502002823187\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 46500\n",
      "Loss 0.09054267059241441\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 46600\n",
      "Loss 0.09022270715217412\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 46700\n",
      "Loss 0.08990510275284862\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 46800\n",
      "Loss 0.08958983084961623\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 46900\n",
      "Loss 0.08927686529965352\n",
      "3 + 5 = 8\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 47000\n",
      "Loss 0.08896618035446652\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 47100\n",
      "Loss 0.08865775065246179\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 47200\n",
      "Loss 0.0883515512115659\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 47300\n",
      "Loss 0.08804755742217105\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 47400\n",
      "Loss 0.08774574504007751\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 47500\n",
      "Loss 0.08744609017973365\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 47600\n",
      "Loss 0.08714856930750882\n",
      "1 + 5 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 47700\n",
      "Loss 0.08685315923524366\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 47800\n",
      "Loss 0.08655983711380877\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 47900\n",
      "Loss 0.08626858042692681\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 48000\n",
      "Loss 0.085979366985026\n",
      "2 + 0 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 48100\n",
      "Loss 0.08569217491933988\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 48200\n",
      "Loss 0.08540698267601848\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 48300\n",
      "Loss 0.0851237690104671\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 48400\n",
      "Loss 0.08484251298175605\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 48500\n",
      "Loss 0.08456319394716134\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 48600\n",
      "Loss 0.08428579155682306\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 48700\n",
      "Loss 0.0840102857485316\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 48800\n",
      "Loss 0.08373665674261611\n",
      "0 + 4 = 4\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Iteration 48900\n",
      "Loss 0.08346488503692878\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 49000\n",
      "Loss 0.08319495140196496\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 49100\n",
      "Loss 0.08292683687607103\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 49200\n",
      "Loss 0.08266052276073116\n",
      "3 + 6 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 49300\n",
      "Loss 0.08239599061601283\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 49400\n",
      "Loss 0.0821332222560406\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 49500\n",
      "Loss 0.08187219974460863\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 49600\n",
      "Loss 0.08161290539088242\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 49700\n",
      "Loss 0.08135532174515388\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 49800\n",
      "Loss 0.08109943159472832\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 49900\n",
      "Loss 0.08084521795987307\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 50000\n",
      "Loss 0.08059266408985098\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 50100\n",
      "Loss 0.08034175345904042\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 50200\n",
      "Loss 0.08009246976313307\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 50300\n",
      "Loss 0.07984479691540468\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 50400\n",
      "Loss 0.07959871904307271\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 50500\n",
      "Loss 0.0793542204837124\n",
      "4 + 0 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 50600\n",
      "Loss 0.07911128578174552\n",
      "4 + 2 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 50700\n",
      "Loss 0.0788698996850216\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 50800\n",
      "Loss 0.0786300471414441\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 50900\n",
      "Loss 0.07839171329567561\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 51000\n",
      "Loss 0.07815488348589845\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 51100\n",
      "Loss 0.07791954324065048\n",
      "6 + 6 = 12\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 51200\n",
      "Loss 0.07768567827572292\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 51300\n",
      "Loss 0.07745327449109396\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 51400\n",
      "Loss 0.07722231796797485\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 51500\n",
      "Loss 0.0769927949658614\n",
      "6 + 6 = 12\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 51600\n",
      "Loss 0.07676469191966641\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 51700\n",
      "Loss 0.07653799543689949\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 51800\n",
      "Loss 0.07631269229493363\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 51900\n",
      "Loss 0.07608876943824737\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 52000\n",
      "Loss 0.07586621397582882\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 52100\n",
      "Loss 0.07564501317852697\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 52200\n",
      "Loss 0.07542515447650217\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 52300\n",
      "Loss 0.07520662545675341\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 52400\n",
      "Loss 0.07498941386062875\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 52500\n",
      "Loss 0.07477350758139728\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 52600\n",
      "Loss 0.0745588946619325\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 52700\n",
      "Loss 0.07434556329233702\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 52800\n",
      "Loss 0.07413350180771547\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 52900\n",
      "Loss 0.07392269868588737\n",
      "3 + 6 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 53000\n",
      "Loss 0.07371314254522807\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 53100\n",
      "Loss 0.07350482214249171\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 53200\n",
      "Loss 0.07329772637071919\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 53300\n",
      "Loss 0.07309184425713076\n",
      "2 + 4 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 53400\n",
      "Loss 0.07288716496112126\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 53500\n",
      "Loss 0.07268367777224748\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 53600\n",
      "Loss 0.07248137210825471\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 53700\n",
      "Loss 0.07228023751315012\n",
      "2 + 0 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 53800\n",
      "Loss 0.0720802636553342\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 53900\n",
      "Loss 0.07188144032570673\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 54000\n",
      "Loss 0.07168375743586217\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 54100\n",
      "Loss 0.07148720501629402\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 54200\n",
      "Loss 0.07129177321462744\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 54300\n",
      "Loss 0.07109745229390042\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 54400\n",
      "Loss 0.07090423263085417\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 54500\n",
      "Loss 0.07071210471427175\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 54600\n",
      "Loss 0.07052105914333841\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 54700\n",
      "Loss 0.0703310866260275\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 54800\n",
      "Loss 0.07014217797751651\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 54900\n",
      "Loss 0.06995432411864605\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 55000\n",
      "Loss 0.0697675160743846\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 55100\n",
      "Loss 0.0695817449723149\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 55200\n",
      "Loss 0.06939700204119217\n",
      "6 + 6 = 12\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 55300\n",
      "Loss 0.0692132786094553\n",
      "3 + 1 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 55400\n",
      "Loss 0.0690305661038375\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 55500\n",
      "Loss 0.06884885604793928\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 55600\n",
      "Loss 0.0686681400608849\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 55700\n",
      "Loss 0.06848840985593793\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 55800\n",
      "Loss 0.06830965723918245\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 55900\n",
      "Loss 0.06813187410823915\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 56000\n",
      "Loss 0.06795505245094294\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 56100\n",
      "Loss 0.06777918434411384\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 56200\n",
      "Loss 0.06760426195229524\n",
      "5 + 2 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 56300\n",
      "Loss 0.06743027752654342\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 56400\n",
      "Loss 0.06725722340322736\n",
      "4 + 3 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 56500\n",
      "Loss 0.06708509200283971\n",
      "1 + 1 = 2\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 56600\n",
      "Loss 0.06691387582885407\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 56700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.06674356746656326\n",
      "0 + 0 = 0\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 56800\n",
      "Loss 0.06657415958197467\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 56900\n",
      "Loss 0.06640564492069301\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 57000\n",
      "Loss 0.06623801630685333\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 57100\n",
      "Loss 0.06607126664202878\n",
      "5 + 5 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 57200\n",
      "Loss 0.06590538890420115\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 57300\n",
      "Loss 0.0657403761467239\n",
      "6 + 4 = 10\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 57400\n",
      "Loss 0.06557622149730499\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 57500\n",
      "Loss 0.06541291815698377\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 57600\n",
      "Loss 0.06525045939919401\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 57700\n",
      "Loss 0.06508883856876113\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 57800\n",
      "Loss 0.06492804908096673\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 57900\n",
      "Loss 0.06476808442059613\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 58000\n",
      "Loss 0.06460893814103683\n",
      "6 + 3 = 9\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 58100\n",
      "Loss 0.06445060386335003\n",
      "1 + 6 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 58200\n",
      "Loss 0.0642930752754049\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 58300\n",
      "Loss 0.06413634613097013\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 58400\n",
      "Loss 0.06398041024888305\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 58500\n",
      "Loss 0.06382526151214929\n",
      "0 + 5 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 58600\n",
      "Loss 0.06367089386717134\n",
      "0 + 4 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 58700\n",
      "Loss 0.06351730132286776\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 58800\n",
      "Loss 0.06336447794988256\n",
      "5 + 0 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 58900\n",
      "Loss 0.06321241787979953\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 59000\n",
      "Loss 0.06306111530433903\n",
      "0 + 3 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 59100\n",
      "Loss 0.06291056447458951\n",
      "3 + 4 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 59200\n",
      "Loss 0.06276075970023971\n",
      "6 + 1 = 7\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 59300\n",
      "Loss 0.06261169534884169\n",
      "6 + 0 = 6\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 59400\n",
      "Loss 0.062463365845059904\n",
      "5 + 6 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 59500\n",
      "Loss 0.062315765669950736\n",
      "6 + 5 = 11\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 59600\n",
      "Loss 0.06216888936024246\n",
      "2 + 2 = 4\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 59700\n",
      "Loss 0.0620227315076271\n",
      "3 + 0 = 3\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 59800\n",
      "Loss 0.061877286758078374\n",
      "2 + 3 = 5\n",
      "--------------------------\n",
      "--------------------------\n",
      "Iteration 59900\n",
      "Loss 0.061732549811157944\n",
      "5 + 5 = 10\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# used to store loss (used for visualization)\n",
    "err = []\n",
    "\n",
    "# initial step\n",
    "j=0\n",
    "\n",
    "# the training loops\n",
    "while j<training_iter:\n",
    "\n",
    "\toverall = 0.\n",
    "\n",
    "\tdwax = np.zeros_like(wax)\n",
    "\tdway = np.zeros_like(way)\n",
    "\tdwaa = np.zeros_like(waa)\n",
    "\tdba = np.zeros_like(ba)\n",
    "\tdby = np.zeros_like(by)\n",
    "\n",
    "\tfor time in range(1,binary_bit+1):\n",
    "\t\tx = np.array([m_seq[:,binary_bit-time],n_seq[:,binary_bit-time]])\n",
    "\t\ty = np.expand_dims(p_seq[:,binary_bit-time],axis=0)\n",
    "\n",
    "\t\t# forward prop\n",
    "\t\ta[time] = tanh(wax.dot(x) + waa.dot(a[time-1]) + ba)\n",
    "\t\tpred[binary_bit-time] = sigmoid(way.dot(a[time]) + by)\n",
    "\n",
    "\t\toverall += crossentropy(pred[binary_bit-time],y)\n",
    "\n",
    "\t\t# backpropagation\n",
    "\t\terror = pred[binary_bit-time] - y \n",
    "\n",
    "\t\tdway_update = error.dot(a[time].T)\n",
    "\t\tdby_update = np.sum(error,axis=1,keepdims=True)\n",
    "\n",
    "\t\tdza = way.T.dot(error)*tanh(wax.dot(x) + waa.dot(a[time-1]) + ba,deriv=True)\n",
    "\t\tdwax_update = dza.dot(x.T)\n",
    "\t\tdwaa_update = dza.dot(a[time-1].T)\n",
    "\t\tdba_update = np.sum(dza,axis=1,keepdims=True)\n",
    "\n",
    "\t\tdwax += dwax_update\n",
    "\t\tdwaa += dwaa_update\n",
    "\t\tdway += dway_update\n",
    "\t\tdba += dba_update\n",
    "\t\tdby += dby_update\n",
    "\n",
    "\t# store the loss at the current time step\n",
    "\terr.append(overall)\n",
    "\n",
    "\t# update parameters\n",
    "\twax -= alpha*dwax\n",
    "\twaa -= alpha*dwaa\n",
    "\tway -= alpha*dway \n",
    "\tba -= alpha*dba \n",
    "\tby -= alpha*dby\n",
    "\n",
    "\t# display the results\n",
    "\tif j%display_step==0:\n",
    "\t\tprint('--------------------------')\n",
    "\t\tprint('Iteration %d'%j)\n",
    "\t\tprint('Loss %s'%overall)\n",
    "\t\ttest = np.random.randint(m.shape[0])\n",
    "\t\tprediction = [int(pred[i][0,test] >= 0.5) for i in range(binary_bit)]\n",
    "\t\tprint('%d + %d = %d'%(int(m[test]),int(n[test]),binary2int(prediction)))\n",
    "\t\tprint('--------------------------')\n",
    "\n",
    "\tj+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the result, at first, the model makes a silly guest; for example, $6+0=15$. However, after 200 iterations, the model is significantly improved and makes a logical prediction. The graph below shows the performance of the model at each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the results\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Loss through each iterations')\n",
    "plt.plot(np.arange(1,1+len(err)),err,label='loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
